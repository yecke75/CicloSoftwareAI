import argparse
import torch
import torch.nn as nn
import cv2

def run_inference(model_path: str, image_path: str):
    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 
                   'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']
    
    # Define the same model architecture as used during training
    class SimpleCNN(nn.Module):
        def __init__(self):
            super(SimpleCNN, self).__init__()
            self.conv_layers = nn.Sequential(
                nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),
                nn.ReLU(),
                nn.MaxPool2d(kernel_size=2, stride=2),
                nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
                nn.ReLU(),
                nn.MaxPool2d(kernel_size=2, stride=2)
            )
            self.fc_layers = nn.Sequential(
                nn.Linear(64 * 7 * 7, 128),
                nn.ReLU(),
                nn.Linear(128, 10)
            )
        
        def forward(self, x):
            x = self.conv_layers(x)
            x = x.view(x.size(0), -1)
            x = self.fc_layers(x)
            return x

    # Load the model
    model = SimpleCNN()
    model.load_state_dict(torch.load(model_path))
    model.eval()

    # Preprocess the image
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if image is None:
        raise ValueError(f"Image not found or unable to open: {image_path}")
    
    image = cv2.resize(image, (28, 28))
    image = image.astype('float32') / 255.0
    image = torch.tensor(image).unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, 28, 28)

    # Run inference
    print(f"Running inference on image: {image_path} using model {model_path}...")
    with torch.no_grad():
        outputs = model(image)
        _, predicted = torch.max(outputs.data, 1)
    
    predicted_class = class_names[predicted.item()]
    print(f"Predicted class: {predicted_class}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Run inference on a Fashion-MNIST image using a trained model.")
    parser.add_argument("model", type=str, help="Path to the trained model file (e.g., model.pth).", default="persistent_data/model.pth")
    parser.add_argument("image", type=str, help="Path to the input image file (e.g., image.png).", default="persistent_data/sample_image.png")
    args = parser.parse_args()

    run_inference(args.model_path, args.image_path)